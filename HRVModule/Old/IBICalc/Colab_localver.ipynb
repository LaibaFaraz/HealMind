{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a076297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: firebase-admin in d:\\laiba\\desktop\\usm\\cat304w drafts\\working\\healmind_ver2 - copy\\healmind_ver3\\.venv\\lib\\site-packages (7.1.0)\n",
      "Collecting xgboost\n",
      "  Using cached xgboost-3.1.3-py3-none-win_amd64.whl.metadata (2.0 kB)\n",
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.8.0-cp311-cp311-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: pandas in d:\\laiba\\desktop\\usm\\cat304w drafts\\working\\healmind_ver2 - copy\\healmind_ver3\\.venv\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy in d:\\laiba\\desktop\\usm\\cat304w drafts\\working\\healmind_ver2 - copy\\healmind_ver3\\.venv\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: joblib in d:\\laiba\\desktop\\usm\\cat304w drafts\\working\\healmind_ver2 - copy\\healmind_ver3\\.venv\\lib\\site-packages (1.5.3)\n",
      "Collecting schedule\n",
      "  Using cached schedule-1.2.2-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: cachecontrol>=0.14.3 in d:\\laiba\\desktop\\usm\\cat304w drafts\\working\\healmind_ver2 - copy\\healmind_ver3\\.venv\\lib\\site-packages (from firebase-admin) (0.14.4)\n",
      "Requirement already satisfied: google-api-core<3.0.0dev,>=2.25.1 in d:\\laiba\\desktop\\usm\\cat304w drafts\\working\\healmind_ver2 - copy\\healmind_ver3\\.venv\\lib\\site-packages (from google-api-core[grpc]<3.0.0dev,>=2.25.1; platform_python_implementation != \"PyPy\"->firebase-admin) (2.29.0)\n",
      "Requirement already satisfied: google-cloud-firestore>=2.21.0 in d:\\laiba\\desktop\\usm\\cat304w drafts\\working\\healmind_ver2 - copy\\healmind_ver3\\.venv\\lib\\site-packages (from firebase-admin) (2.23.0)\n",
      "Requirement already satisfied: google-cloud-storage>=3.1.1 in d:\\laiba\\desktop\\usm\\cat304w drafts\\working\\healmind_ver2 - copy\\healmind_ver3\\.venv\\lib\\site-packages (from firebase-admin) (3.8.0)\n",
      "Requirement already satisfied: pyjwt>=2.10.1 in d:\\laiba\\desktop\\usm\\cat304w drafts\\working\\healmind_ver2 - copy\\healmind_ver3\\.venv\\lib\\site-packages (from pyjwt[crypto]>=2.10.1->firebase-admin) (2.10.1)\n",
      "Requirement already satisfied: httpx==0.28.1 in d:\\laiba\\desktop\\usm\\cat304w drafts\\working\\healmind_ver2 - copy\\healmind_ver3\\.venv\\lib\\site-packages (from httpx[http2]==0.28.1->firebase-admin) (0.28.1)\n",
      "Requirement already satisfied: anyio in d:\\laiba\\desktop\\usm\\cat304w drafts\\working\\healmind_ver2 - copy\\healmind_ver3\\.venv\\lib\\site-packages (from httpx==0.28.1->httpx[http2]==0.28.1->firebase-admin) (4.12.1)\n",
      "Requirement already satisfied: certifi in d:\\laiba\\desktop\\usm\\cat304w drafts\\working\\healmind_ver2 - copy\\healmind_ver3\\.venv\\lib\\site-packages (from httpx==0.28.1->httpx[http2]==0.28.1->firebase-admin) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\laiba\\desktop\\usm\\cat304w drafts\\working\\healmind_ver2 - copy\\healmind_ver3\\.venv\\lib\\site-packages (from httpx==0.28.1->httpx[http2]==0.28.1->firebase-admin) (1.0.9)\n",
      "Requirement already satisfied: idna in d:\\laiba\\desktop\\usm\\cat304w drafts\\working\\healmind_ver2 - copy\\healmind_ver3\\.venv\\lib\\site-packages (from httpx==0.28.1->httpx[http2]==0.28.1->firebase-admin) (3.11)\n",
      "Requirement already satisfied: h2<5,>=3 in d:\\laiba\\desktop\\usm\\cat304w drafts\\working\\healmind_ver2 - copy\\healmind_ver3\\.venv\\lib\\site-packages (from httpx[http2]==0.28.1->firebase-admin) (4.3.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in d:\\laiba\\desktop\\usm\\cat304w drafts\\working\\healmind_ver2 - copy\\healmind_ver3\\.venv\\lib\\site-packages (from google-api-core<3.0.0dev,>=2.25.1->google-api-core[grpc]<3.0.0dev,>=2.25.1; platform_python_implementation != \"PyPy\"->firebase-admin) (1.72.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in d:\\laiba\\desktop\\usm\\cat304w drafts\\working\\healmind_ver2 - copy\\healmind_ver3\\.venv\\lib\\site-packages (from google-api-core<3.0.0dev,>=2.25.1->google-api-core[grpc]<3.0.0dev,>=2.25.1; platform_python_implementation != \"PyPy\"->firebase-admin) (6.33.4)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in d:\\laiba\\desktop\\usm\\cat304w drafts\\working\\healmind_ver2 - copy\\healmind_ver3\\.venv\\lib\\site-packages (from google-api-core<3.0.0dev,>=2.25.1->google-api-core[grpc]<3.0.0dev,>=2.25.1; platform_python_implementation != \"PyPy\"->firebase-admin) (1.27.0)\n",
      "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in d:\\laiba\\desktop\\usm\\cat304w drafts\\working\\healmind_ver2 - copy\\healmind_ver3\\.venv\\lib\\site-packages (from google-api-core<3.0.0dev,>=2.25.1->google-api-core[grpc]<3.0.0dev,>=2.25.1; platform_python_implementation != \"PyPy\"->firebase-admin) (2.47.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in d:\\laiba\\desktop\\usm\\cat304w drafts\\working\\healmind_ver2 - copy\\healmind_ver3\\.venv\\lib\\site-packages (from google-api-core<3.0.0dev,>=2.25.1->google-api-core[grpc]<3.0.0dev,>=2.25.1; platform_python_implementation != \"PyPy\"->firebase-admin) (2.32.5)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in d:\\laiba\\desktop\\usm\\cat304w drafts\\working\\healmind_ver2 - copy\\healmind_ver3\\.venv\\lib\\site-packages (from google-api-core[grpc]<3.0.0dev,>=2.25.1; platform_python_implementation != \"PyPy\"->firebase-admin) (1.76.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in d:\\laiba\\desktop\\usm\\cat304w drafts\\working\\healmind_ver2 - copy\\healmind_ver3\\.venv\\lib\\site-packages (from google-api-core[grpc]<3.0.0dev,>=2.25.1; platform_python_implementation != \"PyPy\"->firebase-admin) (1.76.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\laiba\\desktop\\usm\\cat304w drafts\\working\\healmind_ver2 - copy\\healmind_ver3\\.venv\\lib\\site-packages (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0dev,>=2.25.1->google-api-core[grpc]<3.0.0dev,>=2.25.1; platform_python_implementation != \"PyPy\"->firebase-admin) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in d:\\laiba\\desktop\\usm\\cat304w drafts\\working\\healmind_ver2 - copy\\healmind_ver3\\.venv\\lib\\site-packages (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0dev,>=2.25.1->google-api-core[grpc]<3.0.0dev,>=2.25.1; platform_python_implementation != \"PyPy\"->firebase-admin) (4.9.1)\n",
      "Requirement already satisfied: typing-extensions~=4.12 in d:\\laiba\\desktop\\usm\\cat304w drafts\\working\\healmind_ver2 - copy\\healmind_ver3\\.venv\\lib\\site-packages (from grpcio<2.0.0,>=1.33.2->google-api-core[grpc]<3.0.0dev,>=2.25.1; platform_python_implementation != \"PyPy\"->firebase-admin) (4.15.0)\n",
      "Requirement already satisfied: hyperframe<7,>=6.1 in d:\\laiba\\desktop\\usm\\cat304w drafts\\working\\healmind_ver2 - copy\\healmind_ver3\\.venv\\lib\\site-packages (from h2<5,>=3->httpx[http2]==0.28.1->firebase-admin) (6.1.0)\n",
      "Requirement already satisfied: hpack<5,>=4.1 in d:\\laiba\\desktop\\usm\\cat304w drafts\\working\\healmind_ver2 - copy\\healmind_ver3\\.venv\\lib\\site-packages (from h2<5,>=3->httpx[http2]==0.28.1->firebase-admin) (4.1.0)\n",
      "Requirement already satisfied: h11>=0.16 in d:\\laiba\\desktop\\usm\\cat304w drafts\\working\\healmind_ver2 - copy\\healmind_ver3\\.venv\\lib\\site-packages (from httpcore==1.*->httpx==0.28.1->httpx[http2]==0.28.1->firebase-admin) (0.16.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\laiba\\desktop\\usm\\cat304w drafts\\working\\healmind_ver2 - copy\\healmind_ver3\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core<3.0.0dev,>=2.25.1->google-api-core[grpc]<3.0.0dev,>=2.25.1; platform_python_implementation != \"PyPy\"->firebase-admin) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\laiba\\desktop\\usm\\cat304w drafts\\working\\healmind_ver2 - copy\\healmind_ver3\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core<3.0.0dev,>=2.25.1->google-api-core[grpc]<3.0.0dev,>=2.25.1; platform_python_implementation != \"PyPy\"->firebase-admin) (2.6.3)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in d:\\laiba\\desktop\\usm\\cat304w drafts\\working\\healmind_ver2 - copy\\healmind_ver3\\.venv\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0dev,>=2.25.1->google-api-core[grpc]<3.0.0dev,>=2.25.1; platform_python_implementation != \"PyPy\"->firebase-admin) (0.6.1)\n",
      "Requirement already satisfied: scipy in d:\\laiba\\desktop\\usm\\cat304w drafts\\working\\healmind_ver2 - copy\\healmind_ver3\\.venv\\lib\\site-packages (from xgboost) (1.15.3)\n",
      "Collecting threadpoolctl>=3.2.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\laiba\\desktop\\usm\\cat304w drafts\\working\\healmind_ver2 - copy\\healmind_ver3\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\laiba\\desktop\\usm\\cat304w drafts\\working\\healmind_ver2 - copy\\healmind_ver3\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\laiba\\desktop\\usm\\cat304w drafts\\working\\healmind_ver2 - copy\\healmind_ver3\\.venv\\lib\\site-packages (from pandas) (2025.3)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=0.5.2 in d:\\laiba\\desktop\\usm\\cat304w drafts\\working\\healmind_ver2 - copy\\healmind_ver3\\.venv\\lib\\site-packages (from cachecontrol>=0.14.3->firebase-admin) (1.1.2)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0,>=1.4.1 in d:\\laiba\\desktop\\usm\\cat304w drafts\\working\\healmind_ver2 - copy\\healmind_ver3\\.venv\\lib\\site-packages (from google-cloud-firestore>=2.21.0->firebase-admin) (2.5.0)\n",
      "Requirement already satisfied: google-resumable-media<3.0.0,>=2.7.2 in d:\\laiba\\desktop\\usm\\cat304w drafts\\working\\healmind_ver2 - copy\\healmind_ver3\\.venv\\lib\\site-packages (from google-cloud-storage>=3.1.1->firebase-admin) (2.8.0)\n",
      "Requirement already satisfied: google-crc32c<2.0.0,>=1.1.3 in d:\\laiba\\desktop\\usm\\cat304w drafts\\working\\healmind_ver2 - copy\\healmind_ver3\\.venv\\lib\\site-packages (from google-cloud-storage>=3.1.1->firebase-admin) (1.8.0)\n",
      "Requirement already satisfied: cryptography>=3.4.0 in d:\\laiba\\desktop\\usm\\cat304w drafts\\working\\healmind_ver2 - copy\\healmind_ver3\\.venv\\lib\\site-packages (from pyjwt[crypto]>=2.10.1->firebase-admin) (46.0.3)\n",
      "Requirement already satisfied: cffi>=2.0.0 in d:\\laiba\\desktop\\usm\\cat304w drafts\\working\\healmind_ver2 - copy\\healmind_ver3\\.venv\\lib\\site-packages (from cryptography>=3.4.0->pyjwt[crypto]>=2.10.1->firebase-admin) (2.0.0)\n",
      "Requirement already satisfied: pycparser in d:\\laiba\\desktop\\usm\\cat304w drafts\\working\\healmind_ver2 - copy\\healmind_ver3\\.venv\\lib\\site-packages (from cffi>=2.0.0->cryptography>=3.4.0->pyjwt[crypto]>=2.10.1->firebase-admin) (2.23)\n",
      "Requirement already satisfied: six>=1.5 in d:\\laiba\\desktop\\usm\\cat304w drafts\\working\\healmind_ver2 - copy\\healmind_ver3\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Using cached xgboost-3.1.3-py3-none-win_amd64.whl (72.0 MB)\n",
      "Using cached scikit_learn-1.8.0-cp311-cp311-win_amd64.whl (8.1 MB)\n",
      "Using cached schedule-1.2.2-py3-none-any.whl (12 kB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, schedule, xgboost, scikit-learn\n",
      "\n",
      "   ---------------------------------------- 0/4 [threadpoolctl]\n",
      "   -------------------- ------------------- 2/4 [xgboost]\n",
      "   -------------------- ------------------- 2/4 [xgboost]\n",
      "   -------------------- ------------------- 2/4 [xgboost]\n",
      "   -------------------- ------------------- 2/4 [xgboost]\n",
      "   -------------------- ------------------- 2/4 [xgboost]\n",
      "   -------------------- ------------------- 2/4 [xgboost]\n",
      "   -------------------- ------------------- 2/4 [xgboost]\n",
      "   -------------------- ------------------- 2/4 [xgboost]\n",
      "   -------------------- ------------------- 2/4 [xgboost]\n",
      "   -------------------- ------------------- 2/4 [xgboost]\n",
      "   -------------------- ------------------- 2/4 [xgboost]\n",
      "   -------------------- ------------------- 2/4 [xgboost]\n",
      "   -------------------- ------------------- 2/4 [xgboost]\n",
      "   -------------------- ------------------- 2/4 [xgboost]\n",
      "   -------------------- ------------------- 2/4 [xgboost]\n",
      "   -------------------- ------------------- 2/4 [xgboost]\n",
      "   -------------------- ------------------- 2/4 [xgboost]\n",
      "   -------------------- ------------------- 2/4 [xgboost]\n",
      "   -------------------- ------------------- 2/4 [xgboost]\n",
      "   -------------------- ------------------- 2/4 [xgboost]\n",
      "   -------------------- ------------------- 2/4 [xgboost]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ------------------------------ --------- 3/4 [scikit-learn]\n",
      "   ---------------------------------------- 4/4 [scikit-learn]\n",
      "\n",
      "Successfully installed schedule-1.2.2 scikit-learn-1.8.0 threadpoolctl-3.6.0 xgboost-3.1.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies\n",
    "%pip install firebase-admin xgboost scikit-learn pandas numpy joblib schedule\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b12275",
   "metadata": {},
   "source": [
    "How to firebase keyy??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b23ed3",
   "metadata": {},
   "source": [
    "Step by step to get Firebase service account key:\n",
    "\n",
    "Go to: https://console.firebase.google.com\n",
    "\n",
    "Click your existing project (the one with your 2 apps + website)\n",
    "\n",
    "Click the ⚙️ gear icon (top left, next to project name)\n",
    "\n",
    "Click \"Project Settings\"\n",
    "\n",
    "Click the \"Service Accounts\" tab\n",
    "\n",
    "Click the blue \"Generate New Private Key\" button\n",
    "\n",
    "A JSON file downloads to your computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62c6bd8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Firebase initialized! Found key at: d:\\laiba\\Desktop\\USM\\CAT304W Drafts\\Working\\HealMind_ver2 - Copy\\HealMind_Ver3\\healmind-2025-firebase-adminsdk-fbsvc-12242dbda6.json\n"
     ]
    }
   ],
   "source": [
    "#Import and setup fire base no need to upload like in canva\n",
    "import firebase_admin\n",
    "from firebase_admin import credentials, firestore\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from datetime import datetime, timedelta\n",
    "import schedule\n",
    "import time\n",
    "import os\n",
    "\n",
    "def findFirebaseKey():\n",
    "    startPath = os.path.abspath('../../')  # Go up 2 folders\n",
    "    for root, dirs, files in os.walk(startPath):\n",
    "        if 'healmind-2025-firebase-adminsdk-fbsvc-12242dbda6.json' in files:\n",
    "            return os.path.join(root, 'healmind-2025-firebase-adminsdk-fbsvc-12242dbda6.json')\n",
    "    raise FileNotFoundError(\"Firebase key not found!\")\n",
    "\n",
    "cred_path = findFirebaseKey()\n",
    "cred = credentials.Certificate(cred_path)\n",
    "\n",
    "try:\n",
    "    firebase_admin.initialize_app(cred)\n",
    "except ValueError:\n",
    "    pass\n",
    "\n",
    "db = firestore.client()\n",
    "print(f\"Firebase initialized! Found key at: {cred_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa0a30f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model from d:\\laiba\\Desktop\\USM\\CAT304W Drafts\\Working\\HealMind_ver2 - Copy\\HealMind_Ver3\\HRVModule\\XGBoost\\stress_model.pkl\n",
      "loaded scaler from d:\\laiba\\Desktop\\USM\\CAT304W Drafts\\Working\\HealMind_ver2 - Copy\\HealMind_Ver3\\HRVModule\\XGBoost\\scaler.pkl\n",
      "Files loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "# Find the model files\n",
    "def findFiles(filename):\n",
    "    startPath = os.path.abspath('../../')\n",
    "    for root, dirs, files in os.walk(startPath):\n",
    "        if filename in files:\n",
    "            return os.path.join(root, filename)\n",
    "    raise FileNotFoundError(f\"{filename} not found!\")\n",
    "\n",
    "# Load model\n",
    "try:\n",
    "    modelPath = findFiles('stress_model.pkl')\n",
    "    model = joblib.load(modelPath)\n",
    "    print(f\"loaded model from {modelPath}\")\n",
    "except Exception as e:\n",
    "    print(f\"error loading model: {e}\")\n",
    "    model = None\n",
    "\n",
    "# Load scaler\n",
    "try:\n",
    "    scalerPath = findFiles('scaler.pkl')\n",
    "    scaler = joblib.load(scalerPath)\n",
    "    print(f\"loaded scaler from {scalerPath}\")\n",
    "except Exception as e:\n",
    "    print(f\"error loading scaler: {e}\")\n",
    "    scaler = None\n",
    "\n",
    "if model and scaler:\n",
    "    print(\"Files loaded successfully.\")\n",
    "else:\n",
    "    print(\"Error: Model or scaler not loaded properly.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7422f60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch prediction class\n",
    "class StressPredictor:\n",
    "    def __init__(self, model, scaler, db):\n",
    "        self.model = model\n",
    "        self.scaler = scaler\n",
    "        self.db = db\n",
    "        self.feature_names = ['sdnn', 'rmssd']\n",
    "\n",
    "    def fetch_unprocessed_data(self, hours=1):\n",
    "        cutoff_time = datetime.utcnow() - timedelta(hours=hours)\n",
    "\n",
    "        query = self.db.collection('heart_rate_data') \\\n",
    "            .where('timestamp', '>=', cutoff_time) \\\n",
    "            .stream()\n",
    "\n",
    "        data_points = []\n",
    "        for doc in query:\n",
    "            data = doc.to_dict()\n",
    "            data['doc_id'] = doc.id\n",
    "            data_points.append(data)\n",
    "\n",
    "        return pd.DataFrame(data_points) if data_points else pd.DataFrame()\n",
    "\n",
    "    def group_by_window(self, df, window_minutes=5):\n",
    "        if df.empty:\n",
    "            return []\n",
    "\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "        df = df.sort_values('timestamp')\n",
    "\n",
    "        windows = []\n",
    "        for i in range(0, len(df), window_minutes * 12):\n",
    "            window = df.iloc[i:i+window_minutes*12]\n",
    "            if len(window) >= 3:\n",
    "                windows.append(window)\n",
    "\n",
    "        return windows\n",
    "\n",
    "    def process_window(self, window):\n",
    "        all_ibi = []\n",
    "        for ibi_list in window['ibi'].dropna():\n",
    "            if ibi_list:\n",
    "                all_ibi.extend(ibi_list)\n",
    "\n",
    "        if not all_ibi or len(all_ibi) < 2:\n",
    "            return None\n",
    "\n",
    "        ibi = np.array(all_ibi, dtype=float)\n",
    "        sdnn = np.std(ibi)\n",
    "        rmssd = np.sqrt(np.mean(np.diff(ibi) ** 2))\n",
    "\n",
    "        X = np.array([[sdnn, rmssd]])\n",
    "        X_scaled = self.scaler.transform(X)\n",
    "\n",
    "        prediction = self.model.predict(X_scaled)[0]\n",
    "        probability = self.model.predict_proba(X_scaled)[0]\n",
    "\n",
    "        return {\n",
    "            'stress_level': int(prediction),\n",
    "            'stress_probabilities': {\n",
    "                'class_0': float(probability[0]),\n",
    "                'class_1': float(probability[1]) if len(probability) > 1 else 0.0\n",
    "            },\n",
    "            'sdnn': float(sdnn),\n",
    "            'rmssd': float(rmssd),\n",
    "            'window_start': window['timestamp'].min(),\n",
    "            'window_end': window['timestamp'].max(),\n",
    "            'prediction_timestamp': datetime.utcnow(),\n",
    "            'num_samples': len(window)\n",
    "        }\n",
    "\n",
    "    def store_predictions(self, results):\n",
    "        batch = self.db.batch()\n",
    "\n",
    "        for result in results:\n",
    "            doc_ref = self.db.collection('stress_predictions').document()\n",
    "            batch.set(doc_ref, result)\n",
    "\n",
    "        batch.commit()\n",
    "        return len(results)\n",
    "\n",
    "    def run_batch(self, hours=1):\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"BATCH JOB: {datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        print(f\"{'='*60}\")\n",
    "\n",
    "        try:\n",
    "            print(f\"Fetching data from last {hours} hour(s)...\")\n",
    "            df = self.fetch_unprocessed_data(hours=hours)\n",
    "\n",
    "            if df.empty:\n",
    "                print(\"No new data to process\")\n",
    "                return\n",
    "\n",
    "            print(f\"Loaded {len(df)} data points\")\n",
    "\n",
    "            windows = self.group_by_window(df)\n",
    "            print(f\"Created {len(windows)} time windows\")\n",
    "\n",
    "            results = []\n",
    "            for i, window in enumerate(windows):\n",
    "                result = self.process_window(window)\n",
    "                if result:\n",
    "                    results.append(result)\n",
    "\n",
    "            print(f\"Processed {len(results)} windows\")\n",
    "\n",
    "            if results:\n",
    "                stored = self.store_predictions(results)\n",
    "                print(f\"Stored {stored} predictions to Firestore\")\n",
    "\n",
    "                stress_high = sum(1 for r in results if r['stress_level'] == 1)\n",
    "                avg_prob = np.mean([r['stress_probabilities']['class_1'] for r in results])\n",
    "                print(f\"\\nSummary:\")\n",
    "                print(f\"  High stress: {stress_high}/{len(results)}\")\n",
    "                print(f\"  Avg probability: {avg_prob:.2%}\")\n",
    "\n",
    "            print(f\"{'='*60}\\n\")\n",
    "            return results\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {str(e)}\")\n",
    "            return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a200193c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch prediction class\n",
    "class StressPredictor:\n",
    "    def __init__(self, model, scaler, db):\n",
    "        self.model = model\n",
    "        self.scaler = scaler\n",
    "        self.db = db\n",
    "        self.feature_names = ['sdnn', 'rmssd']\n",
    "\n",
    "    def fetch_unprocessed_data(self, hours=1):\n",
    "        cutoff_time = datetime.utcnow() - timedelta(hours=hours)\n",
    "\n",
    "        query = self.db.collection('heart_rate_data') \\\n",
    "            .where('timestamp', '>=', cutoff_time) \\\n",
    "            .stream()\n",
    "\n",
    "        data_points = []\n",
    "        for doc in query:\n",
    "            data = doc.to_dict()\n",
    "            data['doc_id'] = doc.id\n",
    "            data_points.append(data)\n",
    "\n",
    "        return pd.DataFrame(data_points) if data_points else pd.DataFrame()\n",
    "\n",
    "    def group_by_window(self, df, window_minutes=5):\n",
    "        if df.empty:\n",
    "            return []\n",
    "\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "        df = df.sort_values('timestamp')\n",
    "\n",
    "        windows = []\n",
    "        for i in range(0, len(df), window_minutes * 12):\n",
    "            window = df.iloc[i:i+window_minutes*12]\n",
    "            if len(window) >= 3:\n",
    "                windows.append(window)\n",
    "\n",
    "        return windows\n",
    "\n",
    "    def process_window(self, window):\n",
    "        all_ibi = []\n",
    "        for ibi_list in window['ibi'].dropna():\n",
    "            if ibi_list:\n",
    "                all_ibi.extend(ibi_list)\n",
    "\n",
    "        if not all_ibi or len(all_ibi) < 2:\n",
    "            return None\n",
    "\n",
    "        ibi = np.array(all_ibi, dtype=float)\n",
    "        sdnn = np.std(ibi)\n",
    "        rmssd = np.sqrt(np.mean(np.diff(ibi) ** 2))\n",
    "\n",
    "        X = np.array([[sdnn, rmssd]])\n",
    "        X_scaled = self.scaler.transform(X)\n",
    "\n",
    "        prediction = self.model.predict(X_scaled)[0]\n",
    "        probability = self.model.predict_proba(X_scaled)[0]\n",
    "\n",
    "        # Map prediction to stress level label\n",
    "        stress_labels = {0: 'low', 1: 'medium', 2: 'high'}\n",
    "        \n",
    "        return {\n",
    "            'stress_level': int(prediction),\n",
    "            'stress_label': stress_labels[int(prediction)],\n",
    "            'stress_probabilities': {\n",
    "                'class_0_low': float(probability[0]),\n",
    "                'class_1_medium': float(probability[1]) if len(probability) > 1 else 0.0,\n",
    "                'class_2_high': float(probability[2]) if len(probability) > 2 else 0.0\n",
    "            },\n",
    "            'sdnn': float(sdnn),\n",
    "            'rmssd': float(rmssd),\n",
    "            'window_start': window['timestamp'].min(),\n",
    "            'window_end': window['timestamp'].max(),\n",
    "            'prediction_timestamp': datetime.utcnow(),\n",
    "            'num_samples': len(window)\n",
    "        }\n",
    "\n",
    "    def store_predictions(self, results):\n",
    "        batch = self.db.batch()\n",
    "\n",
    "        for result in results:\n",
    "            doc_ref = self.db.collection('stress_predictions').document()\n",
    "            batch.set(doc_ref, result)\n",
    "\n",
    "        batch.commit()\n",
    "        return len(results)\n",
    "\n",
    "    def run_batch(self, hours=1):\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"BATCH JOB: {datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        print(f\"{'='*60}\")\n",
    "\n",
    "        try:\n",
    "            print(f\"Fetching data from last {hours} hour(s)...\")\n",
    "            df = self.fetch_unprocessed_data(hours=hours)\n",
    "\n",
    "            if df.empty:\n",
    "                print(\"No new data to process\")\n",
    "                return\n",
    "\n",
    "            print(f\"Loaded {len(df)} data points\")\n",
    "\n",
    "            windows = self.group_by_window(df)\n",
    "            print(f\"Created {len(windows)} time windows\")\n",
    "\n",
    "            results = []\n",
    "            for i, window in enumerate(windows):\n",
    "                result = self.process_window(window)\n",
    "                if result:\n",
    "                    results.append(result)\n",
    "\n",
    "            print(f\"Processed {len(results)} windows\")\n",
    "\n",
    "            if results:\n",
    "                stored = self.store_predictions(results)\n",
    "                print(f\"Stored {stored} predictions to Firestore\")\n",
    "\n",
    "                # Count each stress level\n",
    "                stress_low = sum(1 for r in results if r['stress_level'] == 0)\n",
    "                stress_medium = sum(1 for r in results if r['stress_level'] == 1)\n",
    "                stress_high = sum(1 for r in results if r['stress_level'] == 2)\n",
    "                \n",
    "                # Average probabilities for each class\n",
    "                avg_prob_low = np.mean([r['stress_probabilities']['class_0_low'] for r in results])\n",
    "                avg_prob_medium = np.mean([r['stress_probabilities']['class_1_medium'] for r in results])\n",
    "                avg_prob_high = np.mean([r['stress_probabilities']['class_2_high'] for r in results])\n",
    "                \n",
    "                print(f\"\\nSummary:\")\n",
    "                print(f\"  Low stress:    {stress_low}/{len(results)} (avg prob: {avg_prob_low:.2%})\")\n",
    "                print(f\"  Medium stress: {stress_medium}/{len(results)} (avg prob: {avg_prob_medium:.2%})\")\n",
    "                print(f\"  High stress:   {stress_high}/{len(results)} (avg prob: {avg_prob_high:.2%})\")\n",
    "\n",
    "            print(f\"{'='*60}\\n\")\n",
    "            return results\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {str(e)}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4698c1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def fetch_unprocessed_data(self, hours=1):\n",
    "        cutoff_time = datetime.utcnow() - timedelta(hours=hours)\n",
    "\n",
    "        # FIX THE WARNING: Use FieldFilter\n",
    "        query = self.db.collection('heart_rate_data') \\\n",
    "            .where(filter=FieldFilter('timestamp', '>=', cutoff_time)) \\\n",
    "            .stream()\n",
    "\n",
    "        data_points = []\n",
    "        for doc in query:\n",
    "            data = doc.to_dict()\n",
    "            data['doc_id'] = doc.id\n",
    "            data_points.append(data)\n",
    "\n",
    "        return pd.DataFrame(data_points) if data_points else pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef6ef10c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing batch processor...\n",
      "\n",
      "============================================================\n",
      "BATCH JOB: 2026-01-15 05:48:49\n",
      "============================================================\n",
      "Fetching data from last 120 hour(s)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\laiba\\Desktop\\USM\\CAT304W Drafts\\Working\\HealMind_ver2 - Copy\\HealMind_Ver3\\.venv\\Lib\\site-packages\\google\\cloud\\firestore_v1\\base_collection.py:316: UserWarning: Detected filter using positional arguments. Prefer using the 'filter' keyword argument instead.\n",
      "  return query.where(field_path, op_string, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1426 data points\n",
      "Created 24 time windows\n",
      "Processed 17 windows\n",
      "Stored 17 predictions to Firestore\n",
      "\n",
      "Summary:\n",
      "  Low stress:    14/17 (avg prob: 63.09%)\n",
      "  Medium stress: 3/17 (avg prob: 28.04%)\n",
      "  High stress:   0/17 (avg prob: 8.87%)\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'stress_level': 0,\n",
       "  'stress_label': 'low',\n",
       "  'stress_probabilities': {'class_0_low': 0.925655722618103,\n",
       "   'class_1_medium': 0.07093185186386108,\n",
       "   'class_2_high': 0.0034124229568988085},\n",
       "  'sdnn': 177.38187506055968,\n",
       "  'rmssd': 228.4857763625561,\n",
       "  'window_start': Timestamp('2026-01-11 13:46:37.004000+0000', tz='UTC'),\n",
       "  'window_end': Timestamp('2026-01-11 13:46:46.096000+0000', tz='UTC'),\n",
       "  'prediction_timestamp': datetime.datetime(2026, 1, 15, 5, 48, 52, 563846),\n",
       "  'num_samples': 60},\n",
       " {'stress_level': 1,\n",
       "  'stress_label': 'medium',\n",
       "  'stress_probabilities': {'class_0_low': 0.46332642436027527,\n",
       "   'class_1_medium': 0.5202280282974243,\n",
       "   'class_2_high': 0.016445549204945564},\n",
       "  'sdnn': 118.04339479850431,\n",
       "  'rmssd': 181.07556903714996,\n",
       "  'window_start': Timestamp('2026-01-11 13:46:46.107000+0000', tz='UTC'),\n",
       "  'window_end': Timestamp('2026-01-11 13:47:22.427000+0000', tz='UTC'),\n",
       "  'prediction_timestamp': datetime.datetime(2026, 1, 15, 5, 48, 52, 567846),\n",
       "  'num_samples': 60},\n",
       " {'stress_level': 1,\n",
       "  'stress_label': 'medium',\n",
       "  'stress_probabilities': {'class_0_low': 0.21742106974124908,\n",
       "   'class_1_medium': 0.7011428475379944,\n",
       "   'class_2_high': 0.08143602311611176},\n",
       "  'sdnn': 50.00828333753183,\n",
       "  'rmssd': 83.6311345532671,\n",
       "  'window_start': Timestamp('2026-01-11 13:53:35.208000+0000', tz='UTC'),\n",
       "  'window_end': Timestamp('2026-01-11 13:53:36.180000+0000', tz='UTC'),\n",
       "  'prediction_timestamp': datetime.datetime(2026, 1, 15, 5, 48, 52, 570846),\n",
       "  'num_samples': 60},\n",
       " {'stress_level': 0,\n",
       "  'stress_label': 'low',\n",
       "  'stress_probabilities': {'class_0_low': 0.48809319734573364,\n",
       "   'class_1_medium': 0.30165767669677734,\n",
       "   'class_2_high': 0.21024909615516663},\n",
       "  'sdnn': 124.40251982486332,\n",
       "  'rmssd': 139.21249098790966,\n",
       "  'window_start': Timestamp('2026-01-11 13:53:36.190000+0000', tz='UTC'),\n",
       "  'window_end': Timestamp('2026-01-11 14:43:54.488000+0000', tz='UTC'),\n",
       "  'prediction_timestamp': datetime.datetime(2026, 1, 15, 5, 48, 52, 573847),\n",
       "  'num_samples': 60},\n",
       " {'stress_level': 0,\n",
       "  'stress_label': 'low',\n",
       "  'stress_probabilities': {'class_0_low': 0.5319265127182007,\n",
       "   'class_1_medium': 0.3960011303424835,\n",
       "   'class_2_high': 0.07207238674163818},\n",
       "  'sdnn': 119.31073674700943,\n",
       "  'rmssd': 138.05960504598926,\n",
       "  'window_start': Timestamp('2026-01-11 14:44:10.360000+0000', tz='UTC'),\n",
       "  'window_end': Timestamp('2026-01-11 17:03:17.658000+0000', tz='UTC'),\n",
       "  'prediction_timestamp': datetime.datetime(2026, 1, 15, 5, 48, 52, 576846),\n",
       "  'num_samples': 60},\n",
       " {'stress_level': 0,\n",
       "  'stress_label': 'low',\n",
       "  'stress_probabilities': {'class_0_low': 0.7144384980201721,\n",
       "   'class_1_medium': 0.26547425985336304,\n",
       "   'class_2_high': 0.020087264478206635},\n",
       "  'sdnn': 161.51064206423055,\n",
       "  'rmssd': 321.973601402351,\n",
       "  'window_start': Timestamp('2026-01-11 17:03:17.699000+0000', tz='UTC'),\n",
       "  'window_end': Timestamp('2026-01-12 20:24:27.252000+0000', tz='UTC'),\n",
       "  'prediction_timestamp': datetime.datetime(2026, 1, 15, 5, 48, 52, 579846),\n",
       "  'num_samples': 60},\n",
       " {'stress_level': 0,\n",
       "  'stress_label': 'low',\n",
       "  'stress_probabilities': {'class_0_low': 0.7361950278282166,\n",
       "   'class_1_medium': 0.2505905330181122,\n",
       "   'class_2_high': 0.013214407488703728},\n",
       "  'sdnn': 118.4523532902576,\n",
       "  'rmssd': 214.32568674799575,\n",
       "  'window_start': Timestamp('2026-01-12 21:16:58.509000+0000', tz='UTC'),\n",
       "  'window_end': Timestamp('2026-01-12 21:17:58.054000+0000', tz='UTC'),\n",
       "  'prediction_timestamp': datetime.datetime(2026, 1, 15, 5, 48, 52, 582847),\n",
       "  'num_samples': 60},\n",
       " {'stress_level': 0,\n",
       "  'stress_label': 'low',\n",
       "  'stress_probabilities': {'class_0_low': 0.7361950278282166,\n",
       "   'class_1_medium': 0.2505905330181122,\n",
       "   'class_2_high': 0.013214407488703728},\n",
       "  'sdnn': 118.45235329025759,\n",
       "  'rmssd': 202.28362926017186,\n",
       "  'window_start': Timestamp('2026-01-12 21:17:58.070000+0000', tz='UTC'),\n",
       "  'window_end': Timestamp('2026-01-12 21:22:33.524000+0000', tz='UTC'),\n",
       "  'prediction_timestamp': datetime.datetime(2026, 1, 15, 5, 48, 52, 585847),\n",
       "  'num_samples': 60},\n",
       " {'stress_level': 0,\n",
       "  'stress_label': 'low',\n",
       "  'stress_probabilities': {'class_0_low': 0.7361950278282166,\n",
       "   'class_1_medium': 0.2505905330181122,\n",
       "   'class_2_high': 0.013214407488703728},\n",
       "  'sdnn': 118.4523532902576,\n",
       "  'rmssd': 214.32568674799575,\n",
       "  'window_start': Timestamp('2026-01-12 21:22:33.534000+0000', tz='UTC'),\n",
       "  'window_end': Timestamp('2026-01-12 21:23:57.453000+0000', tz='UTC'),\n",
       "  'prediction_timestamp': datetime.datetime(2026, 1, 15, 5, 48, 52, 588847),\n",
       "  'num_samples': 60},\n",
       " {'stress_level': 1,\n",
       "  'stress_label': 'medium',\n",
       "  'stress_probabilities': {'class_0_low': 0.39431437849998474,\n",
       "   'class_1_medium': 0.5966148376464844,\n",
       "   'class_2_high': 0.00907077081501484},\n",
       "  'sdnn': 171.42157207277276,\n",
       "  'rmssd': 171.91073264924444,\n",
       "  'window_start': Timestamp('2026-01-12 21:23:57.463000+0000', tz='UTC'),\n",
       "  'window_end': Timestamp('2026-01-14 22:30:00.810000+0000', tz='UTC'),\n",
       "  'prediction_timestamp': datetime.datetime(2026, 1, 15, 5, 48, 52, 591849),\n",
       "  'num_samples': 60},\n",
       " {'stress_level': 0,\n",
       "  'stress_label': 'low',\n",
       "  'stress_probabilities': {'class_0_low': 0.7147417068481445,\n",
       "   'class_1_medium': 0.26447492837905884,\n",
       "   'class_2_high': 0.020783383399248123},\n",
       "  'sdnn': 157.50451888561088,\n",
       "  'rmssd': 214.30890716978539,\n",
       "  'window_start': Timestamp('2026-01-14 22:30:00.820000+0000', tz='UTC'),\n",
       "  'window_end': Timestamp('2026-01-14 23:19:42.496000+0000', tz='UTC'),\n",
       "  'prediction_timestamp': datetime.datetime(2026, 1, 15, 5, 48, 52, 594846),\n",
       "  'num_samples': 60},\n",
       " {'stress_level': 0,\n",
       "  'stress_label': 'low',\n",
       "  'stress_probabilities': {'class_0_low': 0.6958688497543335,\n",
       "   'class_1_medium': 0.1202615275979042,\n",
       "   'class_2_high': 0.18386958539485931},\n",
       "  'sdnn': 40.40721538977359,\n",
       "  'rmssd': 67.46918488533049,\n",
       "  'window_start': Timestamp('2026-01-14 23:19:42.508000+0000', tz='UTC'),\n",
       "  'window_end': Timestamp('2026-01-15 01:54:31.835000+0000', tz='UTC'),\n",
       "  'prediction_timestamp': datetime.datetime(2026, 1, 15, 5, 48, 52, 596846),\n",
       "  'num_samples': 60},\n",
       " {'stress_level': 0,\n",
       "  'stress_label': 'low',\n",
       "  'stress_probabilities': {'class_0_low': 0.47924917936325073,\n",
       "   'class_1_medium': 0.25250205397605896,\n",
       "   'class_2_high': 0.2682487368583679},\n",
       "  'sdnn': 35.59424977835536,\n",
       "  'rmssd': 44.75883087365521,\n",
       "  'window_start': Timestamp('2026-01-15 01:54:31.845000+0000', tz='UTC'),\n",
       "  'window_end': Timestamp('2026-01-15 02:08:15.366000+0000', tz='UTC'),\n",
       "  'prediction_timestamp': datetime.datetime(2026, 1, 15, 5, 48, 52, 599849),\n",
       "  'num_samples': 60},\n",
       " {'stress_level': 0,\n",
       "  'stress_label': 'low',\n",
       "  'stress_probabilities': {'class_0_low': 0.9860357046127319,\n",
       "   'class_1_medium': 0.012386508285999298,\n",
       "   'class_2_high': 0.0015778066590428352},\n",
       "  'sdnn': 200.59950149489407,\n",
       "  'rmssd': 370.5239533417509,\n",
       "  'window_start': Timestamp('2026-01-15 03:58:42.403000+0000', tz='UTC'),\n",
       "  'window_end': Timestamp('2026-01-15 04:06:08.022000+0000', tz='UTC'),\n",
       "  'prediction_timestamp': datetime.datetime(2026, 1, 15, 5, 48, 52, 603846),\n",
       "  'num_samples': 60},\n",
       " {'stress_level': 0,\n",
       "  'stress_label': 'low',\n",
       "  'stress_probabilities': {'class_0_low': 0.48914462327957153,\n",
       "   'class_1_medium': 0.08275274187326431,\n",
       "   'class_2_high': 0.42810264229774475},\n",
       "  'sdnn': 34.17687220548422,\n",
       "  'rmssd': 51.18137682139211,\n",
       "  'window_start': Timestamp('2026-01-15 04:06:08.053000+0000', tz='UTC'),\n",
       "  'window_end': Timestamp('2026-01-15 04:22:09.777000+0000', tz='UTC'),\n",
       "  'prediction_timestamp': datetime.datetime(2026, 1, 15, 5, 48, 52, 605848),\n",
       "  'num_samples': 60},\n",
       " {'stress_level': 0,\n",
       "  'stress_label': 'low',\n",
       "  'stress_probabilities': {'class_0_low': 0.4304909110069275,\n",
       "   'class_1_medium': 0.4188857078552246,\n",
       "   'class_2_high': 0.1506233811378479},\n",
       "  'sdnn': 36.81011240134971,\n",
       "  'rmssd': 56.540756475812586,\n",
       "  'window_start': Timestamp('2026-01-15 04:22:09.789000+0000', tz='UTC'),\n",
       "  'window_end': Timestamp('2026-01-15 04:30:29.188000+0000', tz='UTC'),\n",
       "  'prediction_timestamp': datetime.datetime(2026, 1, 15, 5, 48, 52, 608845),\n",
       "  'num_samples': 60},\n",
       " {'stress_level': 0,\n",
       "  'stress_label': 'low',\n",
       "  'stress_probabilities': {'class_0_low': 0.9860357046127319,\n",
       "   'class_1_medium': 0.012386508285999298,\n",
       "   'class_2_high': 0.0015778066590428352},\n",
       "  'sdnn': 194.9202115966656,\n",
       "  'rmssd': 307.79441190508965,\n",
       "  'window_start': Timestamp('2026-01-15 04:30:29.226000+0000', tz='UTC'),\n",
       "  'window_end': Timestamp('2026-01-15 04:47:27.953000+0000', tz='UTC'),\n",
       "  'prediction_timestamp': datetime.datetime(2026, 1, 15, 5, 48, 52, 610845),\n",
       "  'num_samples': 46}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize and run \n",
    "predictor = StressPredictor(model, scaler, db)\n",
    "\n",
    "print(\"Testing batch processor...\")\n",
    "predictor.run_batch(hours=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38baf0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scheduler started!\n",
      "Will run predictions every 30 minutes\n",
      "\n",
      "Keep this cell running to continue processing...\n",
      "\n",
      "============================================================\n",
      "BATCH JOB: 2026-01-15 05:48:58\n",
      "============================================================\n",
      "Fetching data from last 1 hour(s)...\n",
      "No new data to process\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\laiba\\Desktop\\USM\\CAT304W Drafts\\Working\\HealMind_ver2 - Copy\\HealMind_Ver3\\.venv\\Lib\\site-packages\\google\\cloud\\firestore_v1\\base_collection.py:316: UserWarning: Detected filter using positional arguments. Prefer using the 'filter' keyword argument instead.\n",
      "  return query.where(field_path, op_string, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "BATCH JOB: 2026-01-15 05:49:58\n",
      "============================================================\n",
      "Fetching data from last 1 hour(s)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\laiba\\Desktop\\USM\\CAT304W Drafts\\Working\\HealMind_ver2 - Copy\\HealMind_Ver3\\.venv\\Lib\\site-packages\\google\\cloud\\firestore_v1\\base_collection.py:316: UserWarning: Detected filter using positional arguments. Prefer using the 'filter' keyword argument instead.\n",
      "  return query.where(field_path, op_string, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 200 data points\n",
      "Created 4 time windows\n",
      "Processed 4 windows\n",
      "Stored 4 predictions to Firestore\n",
      "\n",
      "Summary:\n",
      "  Low stress:    4/4 (avg prob: 98.60%)\n",
      "  Medium stress: 0/4 (avg prob: 1.24%)\n",
      "  High stress:   0/4 (avg prob: 0.16%)\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Schedule to run every 30 minutes\n",
    "def job():\n",
    "    predictor.run_batch(hours=1)\n",
    "\n",
    "schedule.every(5).minutes.do(job)\n",
    "\n",
    "print(\"Scheduler started!\")\n",
    "print(\"Will run predictions every 30 minutes\")\n",
    "print(\"\\nKeep this cell running to continue processing...\")\n",
    "job()\n",
    "while True:\n",
    "    schedule.run_pending()\n",
    "    time.sleep(60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
